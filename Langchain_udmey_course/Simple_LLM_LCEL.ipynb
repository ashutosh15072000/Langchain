{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\LANGCHAIN\\langchainenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#### GOOGLE API KEY and Open source models -Llama3.1,Gemma2.mistral --Groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_MODEL_API_KEY\")\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_groq in a:\\langchain\\langchainenv\\lib\\site-packages (0.1.9)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain_groq) (0.9.0)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain_groq) (0.2.26)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (2.6.3)\n",
      "Requirement already satisfied: sniffio in a:\\langchain\\langchainenv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in a:\\langchain\\langchainenv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.10.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (0.1.95)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (23.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (8.2.3)\n",
      "Requirement already satisfied: idna>=2.8 in a:\\langchain\\langchainenv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in a:\\langchain\\langchainenv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.0)\n",
      "Requirement already satisfied: certifi in a:\\langchain\\langchainenv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in a:\\langchain\\langchainenv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in a:\\langchain\\langchainenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in a:\\langchain\\langchainenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain_groq) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in a:\\langchain\\langchainenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (3.9.15)\n",
      "Requirement already satisfied: requests<3,>=2 in a:\\langchain\\langchainenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (2.31.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in a:\\langchain\\langchainenv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in a:\\langchain\\langchainenv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in a:\\langchain\\langchainenv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (2.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -treamlit (a:\\langchain\\langchainenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (a:\\langchain\\langchainenv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C3781FEA60>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C3770A3880>, model_name='Gemma2-9b-It', groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI is a type of artificial intelligence that focuses on **creating new content**. \n",
      "\n",
      "Think of it as a computer program that can learn patterns and structures from existing data, and then use that knowledge to generate something original. This \"something\" can take many forms:\n",
      "\n",
      "* **Text:**  Writing stories, poems, articles, dialogue, code, and more.\n",
      "* **Images:** Creating paintings, photographs, illustrations, and other visual content.\n",
      "* **Audio:** Generating music, sound effects, and realistic speech.\n",
      "* **Video:** Producing short clips, animations, and even entire movies.\n",
      "* **3D Models:** Designing objects, characters, and environments.\n",
      "\n",
      "**How does it work?**\n",
      "\n",
      "Generative AI models are typically trained on massive datasets of existing content. They learn the underlying patterns and relationships within that data, allowing them to generate new content that adheres to similar rules and styles.\n",
      "\n",
      "Some common techniques used in generative AI include:\n",
      "\n",
      "* **Generative Adversarial Networks (GANs):**  These models consist of two competing neural networks: a generator that creates content and a discriminator that tries to distinguish between real and generated content. This adversarial process helps the generator produce increasingly realistic outputs.\n",
      "* **Transformer Networks:**  These models are particularly good at understanding and generating text. They use attention mechanisms to weigh the importance of different words in a sentence, allowing them to capture complex relationships and generate coherent text.\n",
      "\n",
      "**Examples of Generative AI:**\n",
      "\n",
      "* **ChatGPT:** A text-based chatbot that can hold natural-sounding conversations.\n",
      "* **DALL-E 2:**  An image generation model that can create realistic images from text descriptions.\n",
      "* **Jukebox:**  A music generation model that can compose original songs in different genres.\n",
      "\n",
      "**Applications of Generative AI:**\n",
      "\n",
      "Generative AI has a wide range of potential applications, including:\n",
      "\n",
      "* **Creative Industries:**  Writing assistance, concept art, music composition, video game development.\n",
      "* **Marketing and Advertising:**  Generating personalized content, creating ads, designing product packaging.\n",
      "* **Education:**  Creating customized learning materials, generating interactive simulations.\n",
      "* **Research:**  Generating synthetic data for training other AI models, exploring new scientific concepts.\n",
      "\n",
      "\n",
      "Generative AI is a rapidly evolving field with the potential to revolutionize many aspects of our lives.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"What is Generative AI\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "नमस्ते, आप कैसे हैं? \n",
      "(Namaste, aap kaise hain?) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "messages=[\n",
    "    SystemMessage(content=\"Translate the following from English to Hindi\"),\n",
    "    HumanMessage(content=\"Hello How are you?\")\n",
    "]\n",
    "print(llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='नमस्ते, आप कैसे हैं? (Namaste, aap kaise hain?) \\n', response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 26, 'total_tokens': 48, 'completion_time': 0.044, 'prompt_time': 0.004592447, 'queue_time': None, 'total_time': 0.048592447}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ee9013e8-ab97-4d29-8417-c473744caf71-0', usage_metadata={'input_tokens': 26, 'output_tokens': 22, 'total_tokens': 48})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=llm.invoke(messages)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते, आप कैसे हैं? (Namaste, aap kaise hain?) \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser=StrOutputParser()\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते, आप कैसे हैं? (Namaste, aap kaise hain?) \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using LECL - chain the component\n",
    "chain=llm|parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'text'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], template='Translate the following into {language}:')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prompt Templates\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "generic_template=\"Translate the following into {language}:\"\n",
    "\n",
    "prompt=ChatPromptTemplate(\n",
    "    [(\"system\",generic_template),(\"user\",\"{text}\")]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into Hindi:'), HumanMessage(content='hey guys')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re=prompt.invoke({\"language\":\"Hindi\",\"text\":\"hey guys\"})\n",
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following into Hindi:'),\n",
       " HumanMessage(content='hey guys')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते (Namaste) \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=prompt|llm|parser\n",
    "chain.invoke({\"language\":\"Hindi\",\"text\":\"hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
