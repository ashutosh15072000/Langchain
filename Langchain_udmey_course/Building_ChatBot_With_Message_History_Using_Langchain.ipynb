{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "## loading all the enviroments variables\n",
    "load_dotenv()\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<groq.resources.chat.completions.Completions object at 0x0000019E6D27D550> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000019E6BDEC340> model_name='Gemma2-9b-It' groq_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Load the Groq API key from an environment variable\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]\n",
    "\n",
    "# Create a ChatGroq instance with the specified model and API key\n",
    "llm = ChatGroq(model=\"Gemma2-9b-It\", groq_api_key=groq_api_key)\n",
    "\n",
    "# Print the LLM instance (optional)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Ashu, it's nice to meet you! \\n\\nWhat kind of data science work do you do?  Are you working on any interesting projects right now?  \\n\\nI'm always eager to learn more about what data scientists are up to. ðŸ˜Š \\n\\n\", response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 27, 'total_tokens': 86, 'completion_time': 0.121429011, 'prompt_time': 0.002606565, 'queue_time': None, 'total_time': 0.12403557600000001}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-5834fde1-560e-4b37-befe-b4f1fef04e39-0', usage_metadata={'input_tokens': 27, 'output_tokens': 59, 'total_tokens': 86})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The HumanMessage class represents a message that is sent by a human to the language model.\n",
    "from langchain_core.messages import HumanMessage\n",
    "llm.invoke([HumanMessage(content=\"Hi,My name is Ashu and I am a Data Scientist\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Ashu and that you are a Data Scientist!  ðŸ˜Š  \\n\\nIs there anything else you'd like to chat about? Perhaps you have a data science problem you'd like to brainstorm, or you want to know more about how I can be helpful to you in your work.  \\n\\n\", response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 102, 'total_tokens': 171, 'completion_time': 0.142651807, 'prompt_time': 0.006417897, 'queue_time': None, 'total_time': 0.149069704}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-01935f41-e380-494f-afc8-d8999bca0b36-0', usage_metadata={'input_tokens': 102, 'output_tokens': 69, 'total_tokens': 171})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "llm.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi,My name is Ashu and I am a Data Scientist\"),\n",
    "        AIMessage(content=\"Hi Ashu! It's nice to meet you. As a large language model, I'm always interested in learning more about people who work in data science.What kind of data science work do you do? What are you most passionate about in your field?\"),\n",
    "        HumanMessage(content=\"Hey Whats is my name and what do I do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Message History\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of \n",
    "inputs and outputs of the model, and store them in some datastore.Future interaction will then load those \n",
    "messages and pass them into the chain as part of the input .Lets see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in a:\\langchain\\langchainenv\\lib\\site-packages (0.2.10)\n",
      "Requirement already satisfied: PyYAML>=5.3 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain_community) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain_community) (0.6.4)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.9 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain_community) (0.2.11)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain_community) (0.2.26)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain_community) (0.1.95)\n",
      "Requirement already satisfied: numpy<2,>=1 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain_community) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in a:\\langchain\\langchainenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in a:\\langchain\\langchainenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in a:\\langchain\\langchainenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (1.10.13)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in a:\\langchain\\langchainenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (4.10.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in a:\\langchain\\langchainenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.9.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in a:\\langchain\\langchainenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in a:\\langchain\\langchainenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in a:\\langchain\\langchainenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in a:\\langchain\\langchainenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in a:\\langchain\\langchainenv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in a:\\langchain\\langchainenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain_community) (2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in a:\\langchain\\langchainenv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -treamlit (a:\\langchain\\langchainenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (a:\\langchain\\langchainenv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "with_message_history=RunnableWithMessageHistory(llm,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi,My name is Ashu and I am a Data Scientist\")],\n",
    "    config=config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Ashu! It's nice to meet you.\\n\\nAs a large language model, I'm always interested in learning more about the work that data scientists do. What kind of projects are you currently working on? \\n\\nDo you have any questions for me about language models or AI that I could help answer?\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Ashu, as you told me at the beginning of our conversation.  ðŸ˜„ \\n\\nIs there anything else I can help you with?\\n', response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 107, 'total_tokens': 141, 'completion_time': 0.070075014, 'prompt_time': 0.006021397, 'queue_time': None, 'total_time': 0.076096411}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-940f58e2-70b8-4a18-bcd4-fa28828864c8-0', usage_metadata={'input_tokens': 107, 'output_tokens': 34, 'total_tokens': 141})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As an AI, I have no memory of past conversations and do not know your name. Can you tell me? ðŸ˜Š  \\n\\n', response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 18, 'total_tokens': 47, 'completion_time': 0.058485409, 'prompt_time': 0.002346979, 'queue_time': None, 'total_time': 0.060832388}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-69b1784c-c322-452b-afc8-5adf498125e2-0', usage_metadata={'input_tokens': 18, 'output_tokens': 29, 'total_tokens': 47})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config_1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Ram! It's nice to meet you. ðŸ˜Š\\n\\nIs there anything I can help you with today?  \\n\", response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 58, 'total_tokens': 85, 'completion_time': 0.05421865, 'prompt_time': 0.003154678, 'queue_time': None, 'total_time': 0.057373328}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-01bd21cf-f545-4367-abc4-2bdf1c6833c8-0', usage_metadata={'input_tokens': 58, 'output_tokens': 27, 'total_tokens': 85})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"hey my name ram\")],\n",
    "    config=config_1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Ram, you told me a moment ago! ðŸ˜Š \\n\\nDo you want to talk about something else?  Perhaps you'd like to know a fun fact or have me write you a poem?  I'm here to help!  \\n\", response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 97, 'total_tokens': 152, 'completion_time': 0.113131998, 'prompt_time': 0.009070756, 'queue_time': None, 'total_time': 0.122202754}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-cb7b67aa-d0e2-4ca9-be22-5a6c8163799a-0', usage_metadata={'input_tokens': 97, 'output_tokens': 55, 'total_tokens': 152})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config_1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
