{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Managing The Conversation History\n",
    "- The conversation history is a critical component of the conversation. It is the record of all the messages exchanged\n",
    "- One important concept to understand when building the chatbots is how to mange conversation history.If left unmanaged,the list of messages will grow unbounded and potentially overflow the context window of the LLM.Therefore,it is important to add a step that limits the size of the messages you are passing in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<groq.resources.chat.completions.Completions object at 0x0000021A10163130> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000021A10163D30> model_name='Gemma2-9b-It' groq_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import AIMessage\n",
    "from dotenv import load_dotenv\n",
    "## loading all the enviroments variables\n",
    "load_dotenv()\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Load the Groq API key from an environment variable\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]\n",
    "\n",
    "# Create a ChatGroq instance with the specified model and API key\n",
    "llm = ChatGroq(model=\"Gemma2-9b-It\", groq_api_key=groq_api_key)\n",
    "\n",
    "# Print the LLM instance (optional)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a good assistant'),\n",
       " HumanMessage(content='I like vanilla ice cream'),\n",
       " AIMessage(content='Nice'),\n",
       " HumanMessage(content='Whats 2+2'),\n",
       " AIMessage(content='4'),\n",
       " HumanMessage(content='Thanks'),\n",
       " AIMessage(content='No Problem'),\n",
       " HumanMessage(content='Having Fun?'),\n",
       " AIMessage(content='Yes!')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=llm,    \n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    "\n",
    ")\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"You are a good assistant\"),\n",
    "    HumanMessage(content=\"Hi!,I am bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"Nice\"),\n",
    "    HumanMessage(content=\"Whats 2+2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"Thanks\"),\n",
    "    AIMessage(content=\"No Problem\"),\n",
    "    HumanMessage(content=\"Having Fun?\"),\n",
    "    AIMessage(content=\"Yes!\")\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "         \"You are a helpful assistant.Answer all the question to the nest of your ability in {language}\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have access to your personal information or preferences, so I wouldn't know your favorite ice cream! \\n\\nWhat's your favorite flavor?  ðŸ¦ðŸ˜Š\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    |prompt\n",
    "    |llm\n",
    ")\n",
    "\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"what ice cream do i like\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"Whats 2+2\".  ðŸ˜Š  \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"what math problem did I ask?\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "with_message_history=RunnableWithMessageHistory(llm,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets wrap this in the Message History\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "config={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have access to any personal information about you, including your name.  \\n\\nDo you want to tell me your name? ðŸ˜Š \\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"what is my name?\")],\n",
    "    \"language\":\"English\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
